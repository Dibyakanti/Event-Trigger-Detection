{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import sys\n",
    "\n",
    "sys.path.append(\"./scripts/\") # put the path where the scripts are stored\n",
    "\n",
    "!pip install torch==1.1.0\n",
    "!pip install pytorch-pretrained-bert==0.6.2\n",
    "\n",
    "!python -m spacy download en_core_web_sm\n",
    "!python -m spacy download en"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "creating the dataset\n",
    "'''\n",
    "from convertBrat import *\n",
    "\n",
    "kag_addr = \"./\"\n",
    "folder = kag_addr+\"./data/brat\"\n",
    "outdirr = \"/output/\"+\"./data/tsv\"\n",
    "\n",
    "os.makedirs(\"%s/%s\" % (outdirr, \"train\"))\n",
    "os.makedirs(\"%s/%s\" % (outdirr, \"dev\"))\n",
    "os.makedirs(\"%s/%s\" % (outdirr, \"test\"))\n",
    "\n",
    "train, dev, test=read_splits(kag_addr+\"./data/train.ids\", kag_addr+\"./data/dev.ids\", kag_addr+\"./data/test.ids\")\n",
    "\n",
    "onlyfiles = [f for f in listdir(folder) if isfile(join(folder, f))]\n",
    "\n",
    "for filename in onlyfiles:\n",
    "    if filename.endswith(\".txt\"):\n",
    "        base=re.sub(\".txt\", \"\", filename.split(\"/\")[-1])\n",
    "        print(base)\n",
    "\n",
    "        textFile=\"%s/%s.txt\" % (folder, base)\n",
    "        annFile=\"%s/%s.ann\" % (folder, base)\n",
    "\n",
    "        outDir=None\n",
    "        if base in train:\n",
    "            outDir=os.path.join(outdirr, \"train\")\n",
    "        elif base in dev:\n",
    "            outDir=os.path.join(outdirr, \"dev\")\n",
    "        elif base in test:\n",
    "            outDir=os.path.join(outdirr, \"test\")\n",
    "\n",
    "        outFile=os.path.join(outDir, \"%s.tsv\" % base)\n",
    "\n",
    "        anns=read_ann(annFile)\n",
    "        read_txt(textFile, anns, outFile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Make bert_feature_vectors from the dataset\n",
    "'''\n",
    "from return_bert_features import *\n",
    "\n",
    "train_list = list(train.keys())\n",
    "dev_list = list(dev.keys())\n",
    "test_list = list(test.keys())\n",
    "\n",
    "def loop(i,dataset):\n",
    "    args = {}\n",
    "    args[\"file\"]=\"/output\"+\"/data/tsv/\"+dataset+\"/\"+i\n",
    "    args[\"model_path\"]=\"bert-base-cased\"\n",
    "    args[\"output\"]=\"/output\"+\"/data/bert/\"+dataset+\"/\"+i\n",
    "\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    print('')\n",
    "    print(\"********************************************\")\n",
    "    print(\"Running on: {}\".format(device))\n",
    "    print(\"Using the following model: {}\".format(args[\"model_path\"]))\n",
    "    print(\"********************************************\")\n",
    "    print('')\n",
    "\n",
    "    sents, orig_lines = read_sentences([args[\"file\"]])\n",
    "\n",
    "    berts = get_bert_representations(args[\"model_path\"], sents)\n",
    "\n",
    "    with open(args[\"output\"], \"w\", encoding=\"utf-8\") as out:\n",
    "        for idx, bert in enumerate(berts):\n",
    "            orig=orig_lines[idx]\n",
    "            for i in range(len(orig)):\n",
    "                out.write(\"%s\\t%s\\n\" % (orig[i], ' '.join(str(x) for x in bert[i])))\n",
    "            out.write(\"\\n\")\n",
    "\n",
    "\n",
    "dataset=\"train\"\n",
    "os.makedirs(\"/output/data/bert/\"+dataset+\"/\")\n",
    "for i in train_list:\n",
    "    i = i+\".tsv\"\n",
    "    loop(i,dataset)\n",
    "\n",
    "dataset=\"dev\"\n",
    "os.makedirs(\"/output/data/bert/\"+dataset+\"/\")\n",
    "for i in dev_list:\n",
    "    i = i+\".tsv\"\n",
    "    loop(i,dataset)\n",
    "\n",
    "dataset=\"test\"\n",
    "os.makedirs(\"/output/data/bert/\"+dataset+\"/\")\n",
    "for i in test_list:\n",
    "    i = i+\".tsv\"\n",
    "    loop(i,dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Get the gutebnerg vectors for using the word embeddings\n",
    "'''\n",
    "%%bash\n",
    "wget http://people.ischool.berkeley.edu/~dbamman/data/guten.vectors.txt.gz\n",
    "gunzip guten.vectors.txt.gz\n",
    "# mkdir ./data\n",
    "mv guten.vectors.txt ./data/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
